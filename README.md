# Обнаружение необычной человеческой деятельности (используя видео с CCTV-камеры)
Это `Python2` реализация алгоритма, описанного в данном документе: 
 
https://ieeexplore.ieee.org/document/7024902

## Датасет
Данные для теста взяты здесь, чтобы обнаружить необычную деятельность человека в видео:

http://www.svcl.ucsd.edu/projects/anomaly/

## Аннотация

В связи с увеличением количества массовых мероприятий, безопасность в последнее время приобретает первостепенное значение. 
Многие организации устанавливают системы видеонаблюдения для постоянного наблюдения за людьми и их взаимодействиями. 
Для развитой страны с населением в 40 миллионов человек каждый человек снимается камерой около 30 раз в день. 
Много видео генерируется и хранится в течение определенного времени (в среднем около 30 дней). 
Изображение с разрешением 704x576, записанное со скоростью 25 кадров в секунду за весь день, будет занимать 20 ГБ на носителе. 
Поскольку постоянный мониторинг данных людьми, чтобы оценивать, являются ли события в кадре ненормальными, является почти невозможной задачей, так как это требует дополнительной рабочей силы и их постоянного внимания. 
Это создает необходимость автоматизировать это действие.

Кроме того, необходимо показать, в каком кадре и в каких его частях содержится необычная активность, что помогает быстрее судить о ненормальной активности. 
Метод включает в себя создание карты влияния движения, чтобы представить взаимодействия, захваченные в кадре. 
Основной характерной особенностью предлагаемой карты влияния движения является то, что она эффективно отображает характеристики движения: скорости, направления, размера объектов и их взаимодействия в последовательности кадров.
Кроме того, скрипт извлекает кадры с завышенными значениями влияния движения и сравнивает их с кадрами тестирования для автоматического обнаружения глобальных и локальных необычных действий.

## Установка зависомостей
Тут используется `Python2`, установка зависимостей происходит с помощью команды:

```shell script
 pip install -r requirements.txt
```

(желательно использование `virtualenv`)

## Реализация

Код разделен на 5 файлов, это:
* `optFlowOfBlocks.py`
* `motionInfluenceGenerator.py`
* `CreateMegaBlocks.py`
* `training.py`
* `testing.py`

В этом разделе описывается способ представления характеристик движения для обнаружения и локализации необычных действий в людном месте. 
Здесь следует отметить, что рассмотрены были два типа необычных действий:
* локальные 
* глобальные

Локальные необычные действия происходят в относительно небольшой области.
В части кадра могут появляться различные движения, такие как уникальное появление нечеловеческих объектов или быстрое движение человека, когда большинство других пешеходов идут медленно. 

Глобальные необычные действия происходят по всему кадру, например, когда каждый пешеход внутри сцены начинает внезапно бежать, убегая со сцены.

### Ввод и предварительная обработка данных

Видеофайл предоставляется в качестве входных данных для системы, которая подвергается предварительной обработке.
Видео обрабатывается как последовательность изображений, называемых кадрами, и эти кадры обрабатываются последовательно.
RGB изображение сначала преобразуется в изображение оттенков серого. 
Изображение в оттенках серого состоит только из информации об интенсивности изображения, а не из видимых цветов.
Вектор RGB является трехмерным (поскольку он состоит из значений цветов красного, зеленого и синего), тогда как масштабированный вектор серого цвета является одномерным.

###  Оптический поток

После этапа предварительной обработки для каждого кадра в видео оптический поток вычисляется для каждого пикселя в кадре с использованием алгоритма FarneBack.
Оптический поток - это модель видимого движения объектов, поверхностей и краев в визуальной сцене, вызванная относительным движением между наблюдателем и сценой.
Оптический поток представляет собой вектор вида `(r, θ)`, где `r` представляет величину каждого пикселя, а `θ` представляет направление, в котором каждый пиксель перемещался относительно соответствующего пикселя в предыдущих кадрах.

Функция `calcOpticalFlowFarneback()` в OpenCV вычисляет плотный оптический поток, используя алгоритм Gunnar Farneback.

### Оптический поток блоков
#### Разделение кадра на блоки

После вычисления оптических потоков для каждого пикселя в кадре мы разделяем кадр на `M` на `N`однородных блоков без потери общности, где блоки могут быть проиндексирован<ы таким образом `{B1, B2, ..., BMN} `.

#### Расчет оптического потока каждого блока

После разделения кадров на блоки мы вычисляем оптический поток каждого блока, вычисляя среднее значение оптических потоков всех пикселей, составляющих блок.
Оптическим потоком блока является вектор `(r, θ)`, который представляет, сколько сдвинул каждый блок и в каком направлении по сравнению с соответствующим блоком в предыдущих кадрах. 

### Карта влияния движения

На направление движения пешехода в толпе могут влиять различные факторы, такие как препятствия на пути, ближайшие пешеходы и движущийся транспорт.
Мы называем эту характеристику взаимодействия влиянием движения.
Мы предполагаем, что блоки, на которые воздействует движущийся объект, определяются двумя факторами:
* направление движения
* скорость движения

Чем быстрее движется объект, тем больше соседних блоков находятся под воздействием объекта.
Соседние блоки имеют более высокое влияние, чем удаленные блоки.

### Извлечение черт

На карте влияния движения блок, в котором происходит необычная активность, вместе с соседними блоками имеет уникальные векторы влияния движения.
Кроме того, поскольку действие захватывается несколькими последовательными кадрами, мы извлекаем вектор признаков из кубоида, определенного `n × n` блоками, за последние `t` кадров.

#### Создание мегаблоков

Кадры разделены на неперекрывающиеся мегаблоки, каждый из которых представляет собой комбинацию нескольких блоков влияния движения.
Значение влияния движения мегаблока представляет собой сумму значений влияния движения всех меньших блоков, составляющих больший блок.

#### Извлечение черт

После того, как недавнее `t` кадров были разделены на мегаблоки, для каждого мегаблока вектор `8 × t`-мерного каскадного признака извлекается во всех кадрах.
Например, мы берем мегаблок `(1, 1)` из всех кадров (`t` - количество кадров) и объединяем их векторы признаков, чтобы создать объединенный вектор признаков для блока `(1, 1)`.

### Кластеризация

Для каждого мегаблока мы выполняем кластеризацию с использованием пространственно-временных признаков и устанавливаем центры в качестве кодовых слов.
Т.е. для `(i, j)`-го мегаблока у нас есть K кодовых слов.
Здесь следует отметить, что на нашем этапе обучения мы используем только видеоролики с без необычной деятельности.
Поэтому кодовые слова мегаблока моделируют шаблоны обычных действий, которые могут происходить в соответствующей области.

### Фаза тестирования

Теперь, когда мы сгенерировали кодовые слова для обычных действий, пришло время протестировать сгенерированную модель с тестовым набором данных, который содержит необычные действия. 

#### Матрица минимальных расстояний

При тестировании после извлечения векторов пространственно-временных признаков для всех мегаблоков, мы строим матрицу минимального расстояния `E` по мегаблокам, в которой значение элемента определяется минимальным евклидовым расстоянием между вектором признаков текущего тестового кадра и кодовых слов в соответствующем мегаблоке.


## Литература

1. Dong-Gyu Lee, Heung-Il Suk, Sung-Kee Park and Seong-Whan Lee “Motion Influence Map for Unusual Human Activity Detection and Localization in Crowded Scenes” IEEE transactions on circuits and systems for video technology, vol. 25, no. 10, October 2015

2. Датасет – http://mha.cs.umn.edu/Movies/Crowd-Activity-All.avi

3. Датасет - http://www.svcl.ucsd.edu/projects/anomaly/

4. T. Xiang and S. Gong, “Video behavior profiling for anomaly detection,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 30, no. 5, pp. 893–908, May 2008.

5. F. Jiang, J. Yuan, S. A. Tsaftaris, and A. K. Katsaggelos, “Anomalous video event detection using spatiotemporal context,” Comput. Vis. Image Understand., vol. 115, no. 3, pp. 323–333, 2011.

6. B. D. Lucas and T. Kanade, “An iterative image registration technique with an application to stereo vision,” in Proc. 7th Int. Joint Conf. Artif. Intell., San Francisco, CA, USA, Aug. 1981, pp. 674–679.

7. OpenCV Python туториалы http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_tutorials.html 

8. OpenCV документация http://opencv-python-tutroals.readthedocs.io/en/latest/ 